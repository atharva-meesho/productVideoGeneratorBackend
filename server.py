import logging
import base64
from fastapi import FastAPI
from openai import OpenAI
from mock import mock_data
from schema import ProductId
import os
import tempfile

from moviepy.editor import *
from moviepy.video.fx.resize import resize

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# OpenAI client setup
client = OpenAI()

app = FastAPI()

def create_slide(image_path, text, audio_path, duration=5, video_size=(1280, 720)):
    # Load image and resize
    img_clip = ImageClip(image_path).set_duration(duration)
    img_clip = resize(img_clip, width=500)
    img_clip = img_clip.margin(left=50, top=50, bottom=50, right=25, color=(255, 255, 255))

    # Text clip
    txt_clip = TextClip(text, fontsize=36, color='black', font='Arial', size=(video_size[0] - 600, None), method='caption')
    txt_clip = txt_clip.set_duration(duration).set_position(("right", "center"))

    # White background
    bg = ColorClip(size=video_size, color=(255, 255, 255), duration=duration)

    # Compose
    composed = CompositeVideoClip([bg, img_clip.set_position(("left", "center")), txt_clip])

    # Add audio
    audio = AudioFileClip(audio_path)
    composed = composed.set_audio(audio)

    return composed

@app.post("/generate-video")
def generate_video(request: ProductId):
    logger.info("Received request for product_id: %s", request.id)

    # Load mock data
    product_info = mock_data["product_info"]
    images = mock_data["images"]
    num_images = len(images)
    logger.info("Loaded %d images", num_images)

    # Prepare GPT-4 prompt
    prompt = f"""
        You are writing for a product presentation video featuring {num_images} images of a **single product**.

        Write exactly {num_images} short paragraphs — one for each image. Together, these paragraphs should form a **cohesive product pitch**, progressing naturally to build interest and excitement.

        - Each paragraph must highlight a **different, non-repeating feature or aspect** (e.g., design, material, usage, benefits, lifestyle, emotional appeal).
        - Each paragraph should be **under 30 words** to fit on screen.
        - The tone must be friendly, persuasive, and presentation-ready — written for spoken voiceover, shown with a visual.

        Avoid repetition and keep the flow natural — as if one continuous story told through slides.

        Here is the product info to base your writing on:
        \"\"\"{product_info}\"\"\"
    """



    # Call OpenAI for script
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a creative scriptwriter."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=800
    )
    logger.info("Script generated by LLM")

    # Parse paragraphs
    content = response.choices[0].message.content
    paragraphs = [p.strip().strip('"') for p in content.split("\n\n") if p.strip()][:num_images]
    logger.info("Parsed %d paragraph(s)", len(paragraphs))

    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)

    video_paths = []
    paragraph_audio = []
    slide_clips = []

    with tempfile.TemporaryDirectory() as tmpdir:
        for idx, para in enumerate(paragraphs):
            # Generate voiceover
            speech = client.audio.speech.create(
                model="gpt-4o-mini-tts",
                input=para,
                voice="nova",
                response_format="mp3"
            )

            audio_path = os.path.join(tmpdir, f"audio_{idx}.mp3")
            with open(audio_path, "wb") as f:
                f.write(speech.read())

            saved_audio_path = os.path.join(output_dir, f"audio_{idx}.mp3")
            with open(audio_path, "rb") as src, open(saved_audio_path, "wb") as dst:
                dst.write(src.read())
            paragraph_audio.append(saved_audio_path)

            # Create slide
            img_path = images[idx]
            slide = create_slide(img_path, para, saved_audio_path)
            video_path = os.path.join(output_dir, f"slide_{idx}.mp4")
            slide.write_videofile(video_path, fps=24, logger=None)
            slide.close()
            video_paths.append(video_path)

            # Also store clip for final concatenation
            slide_clips.append(VideoFileClip(video_path))

            logger.info("Slide %d saved: %s", idx + 1, video_path)

    # Stitch final video
    final_video_path = os.path.join(output_dir, "final_showcase_video.mp4")
    final_video = concatenate_videoclips(slide_clips, method="compose")
    final_video.write_videofile(final_video_path, fps=24)
    final_video.close()
    video_paths.append(final_video_path)

    logger.info("Final stitched video saved: %s", final_video_path)

    return {
        "paragraphs": paragraphs,
        "audio_paths": paragraph_audio,
        "video_paths": video_paths  # last one is final video
    }
